{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f16a17-ea21-4132-be49-1b41b28129a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/guohao826/AppAlgorithmFace')\n",
    "import cv2\n",
    "import uuid\n",
    "import base64\n",
    "import time\n",
    "import logging\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from src.config import Config\n",
    "from src.service.alive_alg.alive import LiveFaceDetection, check_alive\n",
    "from src.service.face_alg.detect_inference import DetectInference\n",
    "from src.service.face_alg.landmark_inference import LandmarkInference\n",
    "from src.service.face_alg.antispoofing_inference import AntiSpoofingInference\n",
    "\n",
    "from src.service.face_alg.service_demo import PthExtractor, detect_align, get_sim\n",
    "from src.service.image import ImageService\n",
    "from src.util.decorator import catch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c212c-d5a2-4c41-83d4-893b38ae7b84",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a15956-54f0-4d4c-a14b-495ecd007035",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = DetectInference(Config.DETECT_MODEL_PATH, Config.DETECT_GPUID, Config.DETECT_INPUT_SHAPE,\n",
    "                               Config.DETECT_THRESHOLD)\n",
    "landermark_detector = LandmarkInference(Config.DETECT_LANDMARK_MODEL_PATH, Config.DETECT_GPUID)\n",
    "# 活体模型\n",
    "# alive_model = LiveFaceDetection(Config.ALIVE_MODEL_PATH, Config.ALIVE_THRESHOLD_ORIENTATION,\n",
    "#                                     Config.ALIVE_THRESHOLD_MOUSE, Config.ALIVE_THRESHOLD_MOVE,\n",
    "#                                     Config.ALIVE_THRESHOLD_EYE, Config.ALIVE_THRESHOLD_ALIGH,\n",
    "#                                     Config.ALIVE_WIN_WIDTH, Config.ALIVE_WIN_HEIGHT)\n",
    "# 特征检测模型\n",
    "feature_model = PthExtractor(Config.FEATURE_MODEL_PATH,\n",
    "                             Config.FEATURE_MODEL_CONFIG,\n",
    "                             Config.FEATURE_GPUID,\n",
    "                             batch_size=Config.FEATURE_BATCH_SIZE,\n",
    "                             im_shape=Config.FEATURE_INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d777990-034e-459b-812e-1ad0284a5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "##预处理\n",
    "def preprocess(frame):\n",
    "    # img_w = frame.shape[1]\n",
    "    # img_h = frame.shape[0]\n",
    "    # if img_w > img_h:\n",
    "    #     frame = np.rot90(frame)\n",
    "\n",
    "    dim = frame.shape\n",
    "    # resize_w = alive_model.WIN_WIDTH\n",
    "    # resize_h = int(resize_w * dim[0] / dim[1])\n",
    "\n",
    "    # frame = cv2.resize(frame, (resize_w, resize_h))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9729aebb-239d-401b-ac8d-60fe05ab8e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##检测人脸区域\n",
    "def detect_face(frame):\n",
    "    bboxes,lads = detector.detect([frame])\n",
    "    bbox= bboxes[0]\n",
    "    return bbox\n",
    "\n",
    "# def plot_one_box(x, im, label=None, line_thickness=3):\n",
    "    tl = line_thickness or round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = [0,0,255]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    c3 = c1[0],c2[1]\n",
    "    cv2.rectangle(im, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    \n",
    "# def plot_face_region(bboxs,im):\n",
    "    imm = im.copy()\n",
    "    for bbox in bboxs:\n",
    "        plot_one_box(bbox,imm)\n",
    "    return imm\n",
    "    \n",
    "    \n",
    "# def plot_lads(landermarks,frame):\n",
    "    res1 = frame.copy()\n",
    "    # for a in landermark_98.getA()  :\n",
    "        # cv2.circle(res1,(int(a[0]),int(a[1])),2,(0,0,255),-1)\n",
    "    return res1\n",
    "\n",
    "# def get_mouse_status(landmarks_in):\n",
    "    mouseArea = []\n",
    "    for i in range(48, 60):\n",
    "        point = landmarks_in[i]\n",
    "        mouseArea.append([int(point[0, 0]), int(point[0, 1])])\n",
    "    mouseArea = np.array(mouseArea)\n",
    "    mouseSize = cv2.contourArea(mouseArea)\n",
    "    mouseLength = landmarks_in[54][0, 0] - landmarks_in[48][0, 0]\n",
    "    mouseRatio = mouseSize / (mouseLength * mouseLength)\n",
    "    return mouseRatio\n",
    "\n",
    "# def get_eyes_status(landmarks_in):\n",
    "\n",
    "    landmarks_eye = landmarks_in[60:68]\n",
    "    landmarks_right = landmarks_in[68:76]\n",
    "\n",
    "    # left_err = alive_model.eye_aspect_ratio_eight_points(landmarks_eye)\n",
    "    # right_err = alive_model.eye_aspect_ratio_eight_points(landmarks_right)\n",
    "    mean_err = (landmarks_eye + landmarks_right) / 2.0\n",
    "    return mean_err\n",
    "\n",
    "\n",
    "# def getfaceVar(image,face_box, img_w, img_h):\n",
    "    left_x = int(face_box[0])\n",
    "    left_y = int(face_box[1])\n",
    "    right_x = int(face_box[2])\n",
    "    right_y = int(face_box[3])\n",
    "\n",
    "    if left_x < 1:\n",
    "        left_x = 0\n",
    "    if left_y < 1:\n",
    "        left_y = 0\n",
    "    if right_x > (img_w - 1):\n",
    "        right_x = (img_w - 1)\n",
    "    if right_y > (img_h - 1):\n",
    "        right_y = (img_h - 1)\n",
    "\n",
    "    crop_face = image[left_y:right_y, left_x:right_x]\n",
    "    # image = cv2.cvtColor(np.asarray(PIl_image),cv2.COLOR_RGB2BGR)\n",
    "    img2gray = cv2.cvtColor(crop_face, cv2.COLOR_BGR2GRAY)\n",
    "    imageVar = cv2.Laplacian(img2gray, cv2.CV_64F).var()\n",
    "    return imageVar\n",
    "\n",
    "\n",
    "def getImageVar(image):\n",
    "    # image = cv2.cvtColor(np.asarray(PIl_image),cv2.COLOR_RGB2BGR)\n",
    "    img2gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    imageVar = cv2.Laplacian(img2gray, cv2.CV_64F).var()\n",
    "    return imageVar\n",
    "\n",
    "\n",
    "# def isLightnessover( frame, face_box, img_w, img_h):\n",
    "    left_x = int(face_box[0])\n",
    "    left_y = int(face_box[1])\n",
    "    right_x = int(face_box[2])\n",
    "    right_y = int(face_box[3])\n",
    "\n",
    "    if left_x < 1:\n",
    "        left_x = 0\n",
    "    if left_y < 1:\n",
    "        left_y = 0\n",
    "    if right_x > (img_w - 1):\n",
    "        right_x = (img_w - 1)\n",
    "    if right_y > (img_h - 1):\n",
    "        right_y = (img_h - 1)\n",
    "\n",
    "    crop_face = frame[left_y:right_y, left_x:right_x]\n",
    "    img_hsv = cv2.cvtColor(crop_face, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(img_hsv)\n",
    "    bright_value = np.mean(np.mean(v))\n",
    "\n",
    "    # value from [0-255] 0 is dark\n",
    "    if bright_value > 230:\n",
    "        return False\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d51c9c-3084-4173-ad69-308e81a24fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = '/home/guohao826/AppAlgorithmFace/process_file/imgs'\n",
    "root = '/home/guohao826/AppAlgorithmFace/process_file'\n",
    "filenames = os.listdir(dirpath)\n",
    "os.makedirs(os.path.join(root,'no_face'),exist_ok=True)\n",
    "# os.makedirs(os.path.join(root,'mohu'),exist_ok=True)\n",
    "# os.makedirs(os.path.join(root,'light_lack'),exist_ok=True)\n",
    "# os.makedirs(os.path.join(root,'light_over'),exist_ok=True)\n",
    "# os.makedirs(os.path.join(root,'small_face'),exist_ok=True)\n",
    "# os.makedirs(os.path.join(root,'ola'),exist_ok=True)\n",
    "# os.makedirs(os.path.join(root,'eye_close'),exist_ok=True)\n",
    "# os.makedirs(os.path.join(root,'mouse_open'),exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf392a",
   "metadata": {},
   "source": [
    "#### 关键点提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66342659-04e3-4fe6-a513-78c2b201e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(filenames):\n",
    "    try:\n",
    "        #filename = 'base_20211219174036f5fd906f42ca40db82b532e07bf5215a.jpg'\n",
    "        img_path = os.path.join(dirpath,filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        #img = cv2.imread('./eye.jpg')\n",
    "        frame = preprocess(img)\n",
    "        bounding_boxes = detect_face(frame)\n",
    "        dim = frame.shape\n",
    "        img_h = dim[0]\n",
    "        img_w = dim[1]\n",
    "        if len(bounding_boxes) > 0:\n",
    "            # index = alive_model.maxbox(bounding_boxes)\n",
    "            # box = bounding_boxes[index]\n",
    "            # isLightover = isLightnessover(frame, box, img_w, img_h)\n",
    "            # isLightFace = alive_model.isLightnessEnough(frame, box, img_w, img_h)\n",
    "            # isBigFace = alive_model.isBig(box, img_w, img_h)\n",
    "            ImageVar = getImageVar(frame)\n",
    "            if ImageVar < 10:\n",
    "                target_path = os.path.join(root,'mohu',filename)\n",
    "                shutil.copyfile(img_path,target_path)\n",
    "            # if isLightFace == False:\n",
    "            #     target_path = os.path.join(root,'light_lack',filename)\n",
    "            #     shutil.copyfile(img_path,target_path)\n",
    "            # if isBigFace == False:\n",
    "            #     target_path = os.path.join(root,'small_face',filename)\n",
    "            #     shutil.copyfile(img_path,target_path)\n",
    "            # if isLightover == False:\n",
    "            #     target_path = os.path.join(root,'light_over',filename)\n",
    "            #     shutil.copyfile(img_path,target_path)\n",
    "            ##关键点检测\n",
    "            faceimg, face_size, (x1, y1) = landermark_detector.preprocess(max(bounding_boxes), frame)\n",
    "            landmark_QC = landermark_detector.inference(faceimg, face_size)\n",
    "            # landermark_98 = alive_model.landermark_plus_leftcorner(landmark_QC, np.array([x1, y1]))\n",
    "            # landmarks = alive_model.index_98to68(landmark_QC, np.array([x1, y1]))\n",
    "            # reprojectdst, euler_angle = alive_model.get_head_pose(landmarks)\n",
    "            # aligned_sum = abs(euler_angle[0, 0]) + abs(euler_angle[1, 0]) + abs(euler_angle[2, 0])\n",
    "            # eye_status = get_eyes_status(landermark_98)\n",
    "            # mouse_status = get_mouse_status(landmarks)\n",
    "            # if aligned_sum > 80 :\n",
    "            #     target_path = os.path.join(root,'ola',filename)\n",
    "            #     shutil.copyfile(img_path,target_path)\n",
    "            # elif eye_status<0.11:\n",
    "            #     target_path = os.path.join(root,'eye_close',filename)\n",
    "            #     shutil.copyfile(img_path,target_path)\n",
    "            # elif mouse_status>0.6:\n",
    "            #     target_path = os.path.join(root,'mouse_open',filename)\n",
    "            #     shutil.copyfile(img_path,target_path)\n",
    "\n",
    "            for point in landmark_QC:\n",
    "                cv2.circle(img, (int(point[0] + x1), int(point[1] + y1)), 2, (255, 0, 0), -1)\n",
    "            output_folder = \"/home/guohao826/AppAlgorithmFace/process_file/results1\"\n",
    "            result_img_path = os.path.join(output_folder, 'result_' + filename)\n",
    "            cv2.imwrite(result_img_path, img)\n",
    "        else:\n",
    "            target_path = os.path.join(root,'no_face',filename)\n",
    "            shutil.copyfile(img_path,target_path)\n",
    "    except:\n",
    "        print(filename)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122f580",
   "metadata": {},
   "source": [
    "## 人脸比对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da611a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compare_score(feature_1, feature_2):\n",
    "    '''\n",
    "    根据特征计算相似度得分\n",
    "    '''\n",
    "    return get_sim(feature_1, feature_2)\n",
    "\n",
    "\n",
    "def get_feature_value(base64_str=None, url=None, image=None):\n",
    "    '''\n",
    "    base64_str: 图片 base64 字符串\n",
    "    url: 图片 url\n",
    "    image: cv2 的 image 对象\n",
    "    依次判断三个参数，任一个满足时开始进行特征提取\n",
    "    返回识别的特征值\n",
    "    '''\n",
    "    # 处理二进制\n",
    "    if base64_str is not None:\n",
    "        binary = base64.b64decode(base64_str)\n",
    "    elif url is not None:\n",
    "        binary = ImageService.download_image(url)\n",
    "    else:\n",
    "        binary = None\n",
    "    # 二进制或 image 对象需要至少存在一个\n",
    "    if binary is None and image is None:\n",
    "        return None\n",
    "    filename = uuid.uuid4().hex\n",
    "    if binary is not None:\n",
    "        # buf = np.asarray(bytearray(binary), dtype=\"uint8\")\n",
    "        buf = np.frombuffer(binary, dtype=\"uint8\")\n",
    "        image = cv2.imdecode(buf, cv2.IMREAD_COLOR)\n",
    "    logging.debug(\"detect start: %s\", time.time())\n",
    "    key_imarray_map = detect_align(detector, {filename: image}, align_shape=Config.DETECT_ALIGN_SHAPE)\n",
    "    logging.debug(\"detect done: %s\", time.time())\n",
    "    feature_map = feature_model.inference(key_imarray_map)\n",
    "    logging.debug(\"feature done: %s\", time.time())\n",
    "    return feature_map[filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7907387",
   "metadata": {},
   "source": [
    "### 导入视频进行人脸比对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a72ab097",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'await' outside async function (318083820.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    detect_feature = await get_feature_value(image=frame)\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'await' outside async function\n"
     ]
    }
   ],
   "source": [
    "#提取视频人脸帧\n",
    "def process_video(frame):\n",
    "    # 人脸检测\n",
    "    frame = preprocess(frame)\n",
    "    bounding_boxes = detect_face(frame)\n",
    "    # 检测到人脸的标志\n",
    "    face_detected = False\n",
    "    if len(bounding_boxes) > 0:\n",
    "        face_detected = True\n",
    "    return face_detected\n",
    "\n",
    "\n",
    "#对每一帧进行人脸比对\n",
    "# async def process_frame(frame,base_img):\n",
    "    detect_feature = await get_feature_value(image=frame)\n",
    "    base_feature = await get_feature_value(image=base_img)\n",
    "    data_score = get_compare_score(detect_feature, base_feature)\n",
    "    # print(data_score)\n",
    "    data_ismatch = True if data_score >= Config.FEATURE_MATCH_THRESHOLD else False\n",
    "    return data_ismatch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a087309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/guohao826/AppAlgorithmFace/material/input_video/2.mp4\"\n",
    "output_folder = \"/home/guohao826/AppAlgorithmFace/material/output_frame\"\n",
    "base_img_path = '/home/guohao826/AppAlgorithmFace/material/images/oppen.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea06d4",
   "metadata": {},
   "source": [
    "#### 处理视频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38165580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开视频文件\n",
    "video = cv2.VideoCapture(video_path)\n",
    "# 获取视频的帧率\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "# 获取视频的宽度和高度\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# 记录有人脸的帧数\n",
    "frames_with_face = 0\n",
    "# 创建输出文件夹\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "# 遍历视频的每一帧\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    # 如果没有帧了，退出循环\n",
    "    if not ret:\n",
    "        break\n",
    "    # 人脸检测\n",
    "    face_detected = process_video(frame)\n",
    "    # 保存有人脸的帧\n",
    "    if face_detected:\n",
    "        frames_with_face += 1\n",
    "        frame_filename = f\"frame_{frames_with_face}.jpg\"\n",
    "        frame_path = os.path.join(output_folder, frame_filename)\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "# 释放视频流\n",
    "video.release()\n",
    "print(f\"Total frames with face: {frames_with_face}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa7ba5",
   "metadata": {},
   "source": [
    "#### 人脸比对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a823e121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33359/651115605.py:8: RuntimeWarning: coroutine 'get_feature_value' was never awaited\n",
      "  detect_feature = get_feature_value(image=frame)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/tmp/ipykernel_33359/651115605.py:9: RuntimeWarning: coroutine 'get_feature_value' was never awaited\n",
      "  base_feature = get_feature_value(image=base_img)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_985.jpg: False\n",
      "frame_935.jpg: False\n",
      "frame_375.jpg: False\n",
      "frame_536.jpg: True\n",
      "frame_648.jpg: False\n",
      "frame_667.jpg: True\n",
      "frame_346.jpg: False\n",
      "frame_630.jpg: False\n",
      "frame_978.jpg: False\n",
      "frame_549.jpg: False\n",
      "frame_632.jpg: False\n",
      "frame_288.jpg: True\n",
      "frame_817.jpg: True\n",
      "frame_17.jpg: False\n",
      "frame_937.jpg: False\n",
      "frame_1054.jpg: False\n",
      "frame_213.jpg\n",
      "frame_778.jpg: False\n",
      "frame_469.jpg: True\n",
      "frame_779.jpg: False\n",
      "frame_315.jpg: True\n",
      "frame_506.jpg: True\n",
      "frame_246.jpg: False\n",
      "frame_920.jpg: False\n",
      "frame_520.jpg: True\n",
      "frame_560.jpg: False\n",
      "frame_338.jpg: False\n",
      "frame_1040.jpg: False\n",
      "frame_522.jpg: True\n",
      "frame_1074.jpg: False\n",
      "frame_228.jpg: False\n",
      "frame_264.jpg: False\n",
      "frame_646.jpg: False\n",
      "frame_993.jpg: True\n",
      "frame_1090.jpg: False\n",
      "frame_356.jpg: False\n",
      "frame_582.jpg: True\n",
      "frame_705.jpg: True\n",
      "frame_849.jpg: False\n",
      "frame_586.jpg: True\n",
      "frame_385.jpg: False\n",
      "frame_745.jpg: False\n",
      "frame_934.jpg: False\n",
      "frame_148.jpg: True\n",
      "frame_507.jpg: True\n",
      "frame_325.jpg: False\n",
      "frame_397.jpg: False\n",
      "frame_709.jpg: True\n",
      "frame_610.jpg: False\n",
      "frame_568.jpg: False\n",
      "frame_907.jpg: False\n",
      "frame_188.jpg: True\n",
      "frame_647.jpg: False\n",
      "frame_359.jpg: False\n",
      "frame_915.jpg: False\n",
      "frame_800.jpg: False\n",
      "frame_728.jpg: True\n",
      "frame_435.jpg: True\n",
      "frame_885.jpg: True\n",
      "frame_971.jpg: False\n",
      "frame_1046.jpg: False\n",
      "frame_533.jpg: True\n",
      "frame_951.jpg: False\n",
      "frame_442.jpg: True\n",
      "frame_973.jpg: False\n",
      "frame_684.jpg: True\n",
      "frame_842.jpg: False\n",
      "frame_772.jpg: False\n",
      "frame_673.jpg: True\n",
      "frame_495.jpg: True\n",
      "frame_497.jpg: True\n",
      "frame_503.jpg: True\n",
      "frame_233.jpg: False\n",
      "frame_492.jpg: True\n",
      "frame_763.jpg: False\n",
      "frame_378.jpg: False\n",
      "frame_916.jpg: False\n",
      "frame_541.jpg: False\n",
      "frame_125.jpg: True\n",
      "frame_91.jpg: False\n",
      "frame_855.jpg: False\n",
      "frame_945.jpg: False\n",
      "frame_370.jpg: False\n",
      "frame_869.jpg: True\n",
      "frame_11.jpg: False\n",
      "frame_569.jpg: True\n",
      "frame_830.jpg: True\n",
      "frame_1045.jpg: False\n",
      "frame_226.jpg\n",
      "frame_382.jpg: False\n",
      "frame_555.jpg: False\n",
      "frame_550.jpg: False\n",
      "frame_41.jpg: False\n"
     ]
    }
   ],
   "source": [
    "#人脸比对\n",
    "base_img = cv2.imread(base_img_path)\n",
    "framenames = os.listdir(output_folder)\n",
    "for framename in framenames:\n",
    "    try:\n",
    "        frame_path = os.path.join(output_folder,framename)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        detect_feature = get_feature_value(image=frame)\n",
    "        base_feature = get_feature_value(image=base_img)\n",
    "        data_score = get_compare_score(detect_feature, base_feature)\n",
    "        # print(data_score)\n",
    "        data_ismatch = True if data_score >= Config.FEATURE_MATCH_THRESHOLD else False\n",
    "        if data_ismatch:\n",
    "            print(framename+': True')\n",
    "        else:\n",
    "            print(framename+\": False\")\n",
    "    except:\n",
    "        print(framename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19663f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_img = cv2.imread('/home/guohao826/AppAlgorithmFace/process_file/imgs/2.png')\n",
    "# img = cv2.imread('/home/guohao826/AppAlgorithmFace/process_file/imgs/1.png')\n",
    "# detect_feature = await get_feature_value(image=img)\n",
    "# base_feature = await get_feature_value(image=base_img)\n",
    "# data_score = get_compare_score(detect_feature, base_feature)\n",
    "#     # print(data_score)\n",
    "# data_ismatch = True if data_score >= Config.FEATURE_MATCH_THRESHOLD else False\n",
    "# # data_ismatch = process_frame(img, base_img)\n",
    "# if data_ismatch:\n",
    "#     print('jpg : True')\n",
    "# else:\n",
    "#     print(\"jpg : False\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
